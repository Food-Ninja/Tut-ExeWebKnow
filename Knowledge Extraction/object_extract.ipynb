{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02029bf",
   "metadata": {},
   "source": [
    "# Extraction of Relevant Object Knowledge from the Web\n",
    "\n",
    "Before starting this tutorial, make sure the necessary packages are installed (see requirements.txt). Additionally, the following files need to be downloaded / extracted into this folder. You can either download them separately as explained below, our you download them all at once [here](https://uni-bielefeld.sciebo.de/s/n88qgNmzCzYOlhh).\n",
    "\n",
    "- *foodon.owl* - FoodOn used for extracting information about fruits and vegetables (found [here](https://github.com/FoodOntology/foodon))\n",
    "- *numberbatch-en.txt* - ConceptNet Numberbatch embeddings for object property extraction (download *English-only V. 19.08* from [here](https://github.com/commonsense/conceptnet-numberbatch?tab=readme-ov-file#downloads))\n",
    "- *NASARI_embed_english.txt* - NASARI embeddings also used for object property extraction (download *English - Embed(Wiki)* from [here](http://lcl.uniroma1.it/nasari/#two))\n",
    "\n",
    "Throughout the tutorial, we will import multiple different .csv files that have been created with additional tools. Due to the time constraints of the tutorial and to keep the interactivity as high as possible, we will not look into the inner workings or the usage of these two tools but just use their extracted results.\n",
    "- [WikiHow Analysis Tool](https://github.com/Food-Ninja/WikiHow-Instruction-Extraction)\n",
    "- [Recipe1M+ Analyser](https://github.com/Food-Ninja/RecipeAnalysis)\n",
    "\n",
    "In general, the extraction of knowledge about different objects and their task-specific properties consists of four main steps:\n",
    "\n",
    "1. Choosing a group of relevant objects (e.g. 'Fruits & Vegetables')\n",
    "2. Gathering all available objects of that group from a suitable taxonomy or ontology (e.g. FoodOn)\n",
    "3. Filtering the extracted objects using fitting text corpora (e.g. Recipe1M+)\n",
    "4. Gathering information about task-specific properties using 3 different word embeddings (GloVe, NASARI & ConceptNet Numberbatch) and a recipe corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from rdflib import Graph, Literal, Namespace, RDF, RDFS, URIRef\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eab54d",
   "metadata": {},
   "source": [
    "### Extracting fruits and vegetables from the FoodOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ontology and set the namespace prefixes\n",
    "foodon_loc = \"./foodon.owl\"\n",
    "g = Graph()\n",
    "g.parse(foodon_loc)\n",
    "\n",
    "FOOD = Namespace(\"http://purl.obolibrary.org/obo/\")\n",
    "RDFS = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "# get the fruit data through the SPARQL query \n",
    "query = prepareQuery(   \n",
    "    \"\"\"\n",
    "    SELECT ?fruit_label (SAMPLE(?fruit_id) AS ?rndm_fruit_id) (SAMPLE(?def) AS ?rndm_def)\n",
    "    WHERE {\n",
    "        ?fruit_id rdfs:label ?label.\n",
    "        ?fruit_id rdfs:subClassOf+ food:PO_0009001.\n",
    "        OPTIONAL { ?fruit_id food:IAO_0000115 ?def. }\n",
    "\n",
    "        BIND (LCASE(STR(?label)) AS ?str_label).\n",
    "        BIND (STRBEFORE(?str_label, \"(\") AS ?fruit_label).\n",
    "        FILTER CONTAINS(?str_label, \"whole\").\n",
    "        FILTER NOT EXISTS { ?fruit_id rdfs:subClassOf* food:PO_0030104. }\n",
    "        FILTER (?fruit_id != food:FOODON_03304644).\n",
    "    }\n",
    "    GROUP BY ?fruit_label\n",
    "    ORDER BY ?fruit_label\n",
    "    \"\"\",\n",
    "    initNs={\"food\": FOOD, \"rdfs\": RDFS}\n",
    ")\n",
    "fruits = g.query(query)\n",
    "\n",
    "# get the vegetable data through the SPARQL query \n",
    "query = prepareQuery(\n",
    "    \"\"\"\n",
    "    SELECT ?veg_label (SAMPLE(?veg_id) AS ?rndm_veg_id) (SAMPLE(?def) AS ?rndm_def)\n",
    "    WHERE {\n",
    "        ?veg_id rdfs:label ?label.\n",
    "        ?veg_id rdfs:subClassOf+ food:FOODON_03302008.\n",
    "        OPTIONAL { ?veg_id food:IAO_0000115 ?def. }\n",
    "\n",
    "        BIND (LCASE(STR(?label)) AS ?str_label).\n",
    "        BIND (STRBEFORE(?str_label, \"(\") AS ?veg_label).\n",
    "        FILTER NOT EXISTS { ?veg_id rdfs:subClassOf* food:FOODON_03302007. }\n",
    "    }\n",
    "    GROUP BY ?veg_label\n",
    "    ORDER BY ?veg_label\n",
    "    \"\"\",\n",
    "    initNs={\"food\": FOOD, \"rdfs\": RDFS}\n",
    ")\n",
    "veggies = g.query(query)\n",
    "\n",
    "# convert query results into panda dataframes for further analysis\n",
    "fruit_list = [(str(row[0]), str(row[1]), str(row[2])) for row in fruits]\n",
    "veggie_list = [(str(row[0]), str(row[1]), str(row[2])) for row in veggies]\n",
    "\n",
    "fruit_df = pd.DataFrame(fruit_list, columns=[\"label\", \"rndm_id\", \"rndm_def\"])\n",
    "veggie_df = pd.DataFrame(veggie_list, columns=[\"label\", \"rndm_id\", \"rndm_def\"])\n",
    "combined_df = pd.concat([fruit_df, veggie_df], ignore_index=True)\n",
    "print(f'Fruits: {len(fruit_df)}\\nVegetables: {len(veggie_df)}\\nCombined: {len(combined_df)}')\n",
    "print(combined_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af268b9e",
   "metadata": {},
   "source": [
    "### Filter the fruits and vegetables using WikiHow and Recipe1M+ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec013c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_occurrences = \"./fruit_occurrences.csv\"\n",
    "\n",
    "# read and map the (extracted) occurrence data\n",
    "foc_dat = pd.read_csv(f_occurrences)\n",
    "foc_dat = foc_dat.astype({'Recipes-Title':'int','Recipes-Title [%]':'float', 'Recipes-Steps':'int','Recipes-Steps [%]':'float',\n",
    "                'WikiHow-Title':'int','WikiHow-Title [%]':'float', 'WikiHow-TitleDescription':'int','WikiHow-TitleDescription [%]':'float',\n",
    "                'WikiHow-Method':'int','WikiHow-Method [%]':'float', 'WikiHow-StepHeadline':'int','WikiHow-StepHeadline [%]':'float',\n",
    "                'WikiHow-StepDescription':'int','WikiHow-StepDescription [%]':'float'})\n",
    "\n",
    "# remove all items with too few occurrences in any column (less than 1%)\n",
    "thresh = 0.01\n",
    "most_used = foc_dat[(foc_dat['Recipes-Title [%]'] >= thresh) | (foc_dat['Recipes-Steps [%]'] >= thresh) | (foc_dat['WikiHow-Title [%]'] >= thresh) | \n",
    "                  (foc_dat['WikiHow-TitleDescription [%]'] >= thresh) | (foc_dat['WikiHow-Method [%]'] >= thresh) | (foc_dat['WikiHow-StepHeadline [%]'] >= thresh) |\n",
    "                  (foc_dat['WikiHow-StepDescription [%]'] >= thresh)]\n",
    "print(most_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95610aef",
   "metadata": {},
   "source": [
    "### Extract object properties using 3 different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd262933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the list of possible fruits and possible food parts\n",
    "parts = ['core', 'shell', 'peel', 'stem']\n",
    "foods = list(most_used['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe embeddings\n",
    "glove_sim = 0.25\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
    "\n",
    "for f in foods:\n",
    "    for p in parts:\n",
    "        sim = torch.cosine_similarity(glove[f].unsqueeze(0), glove[p].unsqueeze(0)).item()\n",
    "        if sim >= glove_sim:\n",
    "            print(f'[GloVe] {f} hasPart {p} (Similarity: {sim})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConceptNet Numberbatch embeddings\n",
    "numberbatch_sim = 0.2\n",
    "numberbatch = gensim.models.KeyedVectors.load_word2vec_format('./numberbatch-en.txt', binary=False)\n",
    "\n",
    "# cosine similarity between ConceptNet Numberbatch embeddings\n",
    "for f in foods:\n",
    "    for p in parts:\n",
    "        sim = numberbatch.similarity(f, p)\n",
    "        if sim >= numberbatch_sim:\n",
    "            print(f'[CN Numberbatch] {f} hasPart {p} (Similarity: {sim})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASARI embeddings \n",
    "# Sadly, the BabelNet synsets for core (bn:04772260n) does not exist in the NASARI embeddings and \n",
    "# for 'shell' we need to look for the concrete synset (bn:00071005n) instead \n",
    "parts_nasari = ['bn:00071005n', 'peel_(fruit)', 'plant_stem']\n",
    "nasari_sim = 0.75\n",
    "nasari = gensim.models.KeyedVectors.load_word2vec_format('./NASARI_embed_english.txt', binary=False)\n",
    "               \n",
    "# define function for finding the key based on the given concept name\n",
    "def find_key(concept):\n",
    "    concept_is_synset = \"bn:\" in concept\n",
    "    keys = [key for key in nasari.index_to_key if concept in key.lower()]\n",
    "    for key in keys:\n",
    "        cut = key.split('__')[1].lower()\n",
    "        if (cut == concept and not concept_is_synset) or (concept_is_synset and concept in key.lower()):\n",
    "            return key\n",
    "    return concept\n",
    "    \n",
    "# cosine similarity between NASARI embeddings\n",
    "for f in foods:\n",
    "    for p in parts_nasari:\n",
    "        f_key = find_key(f)\n",
    "        p_key = find_key(p)\n",
    "        if (f_key in nasari.index_to_key) and (p_key in nasari.index_to_key):\n",
    "            sim = nasari.similarity(f_key, p_key)\n",
    "            if sim >= nasari_sim:\n",
    "                print(f'[NASARI] {f} hasPart {p} (Similarity: {sim})')         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ff2ae",
   "metadata": {},
   "source": [
    "### Extract object properties using Recipe1M+ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the (extracted) occurrence data from Recipe1M+\n",
    "p_occurrences = \"./part_occurrences.csv\"\n",
    "poc_dat = pd.read_csv(p_occurrences)\n",
    "print(poc_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the thresholds for the 2-step ('two') and the bigram ('bi') methods\n",
    "bi_recipe_thresh = 0.001\n",
    "bi_step_thresh = 0.001\n",
    "two_recipe_thresh = 0.01\n",
    "two_step_thresh = 0.01\n",
    "\n",
    "parts = ['core', 'shell', 'peel', 'stem']\n",
    "\n",
    "# print object-part-relations\n",
    "for idx, row in poc_dat.iterrows():\n",
    "    for p in parts:\n",
    "        bi_rec_ratio = row[f'bi_{p}_rec'] / row['recipes']\n",
    "        bi_step_ratio = row[f'bi_{p}_step'] / row['steps']\n",
    "        two_rec_ratio = row[f'two_{p}_rec'] / row['recipes']\n",
    "        two_step_ratio = row[f'two_{p}_step'] / row['steps']\n",
    "        \n",
    "        if bi_rec_ratio >= bi_recipe_thresh and bi_step_ratio >= bi_step_thresh:\n",
    "            fruit = row['food']\n",
    "            rec_perc = '{:.2f}'.format(bi_rec_ratio*100)\n",
    "            step_perc = '{:.2f}'.format(bi_step_ratio*100)\n",
    "            print(f'[Bigram] {fruit} hasPart {p} ({rec_perc}% of Recipes & {step_perc}% of Steps)')\n",
    "        \n",
    "        if two_rec_ratio >= two_recipe_thresh and two_step_ratio >= two_step_thresh:\n",
    "            fruit = row['food']\n",
    "            rec_perc = '{:.2f}'.format(two_rec_ratio*100)\n",
    "            step_perc = '{:.2f}'.format(two_step_ratio*100)\n",
    "            print(f'[2-Step] {fruit} hasPart {p} ({rec_perc}% of Recipes & {step_perc}% of Steps)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
