{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02029bf",
   "metadata": {},
   "source": [
    "# Extraction of Relevant Action Knowledge from the Web\n",
    "\n",
    "Before starting this tutorial, make sure the necessary packages are installed (see requirements.txt).\n",
    "Throughout the tutorial, we will import a .csv files that has been created with an external tool ([WikiHow Analysis Tool](https://github.com/Food-Ninja/WikiHow-Instruction-Extraction)). Due to the time constraints of the tutorial and to keep the interactivity as high as possible, we will not look into the inner workings or the usage of this tools but just use the extracted results.\n",
    "\n",
    "In general, the extraction of knowledge about different and relevant actions consists of three main steps:\n",
    "\n",
    "1. Setting the central verb & providing an exemplary sentence (e.g. 'cut')\n",
    "2. Extracting synonyms and hyponyms from WordNet & VerbNet\n",
    "3. Filtering the extracted words on their relevance using a recipe and a WikiHow corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e9ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T12:44:23.298801Z",
     "start_time": "2024-05-13T12:44:23.290357Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "# download wordnet & verbnet corpus\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('verbnet')\n",
    "from nltk.corpus import verbnet, wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ccfc3",
   "metadata": {},
   "source": [
    "### Extracting Synonyms and Hyponyms from WordNet & VerbNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e16ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T12:53:27.876932Z",
     "start_time": "2024-05-13T12:44:30.582012Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the target action\n",
    "target_action = \"cut\"\n",
    "verbs = []\n",
    "\n",
    "# iterating over all WordNet synsets containing the verb and ...\n",
    "synsets = wordnet.synsets(target_action, pos=wordnet.VERB)\n",
    "print(f\"{len(synsets)} synsets found for '{target_action}'\")\n",
    "for syn in synsets:\n",
    "    # ... gathering all synonyms & direct hyponyms\n",
    "    verbs.extend(syn.lemma_names())\n",
    "    for h in syn.hyponyms():\n",
    "        verbs.extend(h.lemma_names())\n",
    "\n",
    "    # ... getting the associated VerbNet class\n",
    "    key = str(syn.lemmas()[0].key()).replace(\"::\", \"\")\n",
    "    vn_classes = verbnet.classids(wordnetid=key)\n",
    "    for vn_class in vn_classes:\n",
    "        verbs.extend(verbnet.lemmas(vn_class))\n",
    "\n",
    "# removing duplicates and printing results\n",
    "verbs = set(verbs)\n",
    "print(f\"{len(verbs)} synonyms or hyponyms found for '{target_action}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eae286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the found synonyms and hyponyms\n",
    "filtered_verbs = {v.split('_')[0] for v in verbs}\n",
    "filtered_verbs = sorted(set(filtered_verbs))\n",
    "\n",
    "print(f\"{len(filtered_verbs)} remaining words:\")\n",
    "for verb in filtered_verbs:\n",
    "    print(verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1eb51",
   "metadata": {},
   "source": [
    "### Filtering the extracted verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f84702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the (extracted) occurrence data\n",
    "v_occurrences = \"./verb_occurrences.csv\"\n",
    "voc_dat = pd.read_csv(v_occurrences)\n",
    "\n",
    "# remove all verbs with 0 occurrences\n",
    "most_used = voc_dat[(voc_dat['SUM'] > 0)]\n",
    "print(f\"{len(most_used)} verbs that occur at least once\")\n",
    "\n",
    "# remove all verbs with too few available sentences (Step Desc <= threshold)\n",
    "thresh = 100\n",
    "most_used = most_used[(most_used['Step Desc'] >= thresh)]\n",
    "print(f\"{len(most_used)} verbs that occur in more than {thresh} step descriptions:\")\n",
    "print(most_used['Verb'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
